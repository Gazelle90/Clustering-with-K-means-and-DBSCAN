{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Step 1: Data Loading and Initial Exploration\n",
    "\n",
    "**Data set**\n",
    "- Load the Mall Customers dataset from the following URL: 'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/Cust_Segmentation.csv'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "\n",
    "# Load the data\n",
    "url = 'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/Cust_Segmentation.csv'\n",
    "\n",
    "s = requests.get(url).content\n",
    "#storing data in mall_customers\n",
    "mall_customers = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "\n",
    "mall_customers.head(5)\n",
    "\n",
    "mall_customers.describe()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Dropping 'Address' (categorical data), 'Customer Id', and 'Defaulted' as they are not suitable for applying  K-means later.\n",
    "# I exclude this feature and proceed with the clustering analysis.\n",
    "\n",
    "mall_customers_to_process = mall_customers.drop(['Address','Customer Id','Defaulted'], axis=1)\n",
    "\n",
    "\n",
    "# storing the columns of the dataframe\n",
    "columns= mall_customers_to_process.columns \n",
    "#removeing missing (NaN) values from the DataFrame and replacing them by their means\n",
    "mall_customers_to_process[columns].fillna(mall_customers_to_process[columns].mean(), inplace=True)\n",
    "#Normalizing the dataset with StandardScaler to ensure that all features in the dataset are on the same scale.\n",
    "scaler = StandardScaler()\n",
    "mall_customers_normalized = pd.DataFrame(scaler.fit_transform(mall_customers_to_process), columns=mall_customers_to_process.columns )\n",
    "\n",
    "mall_customers_normalized.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Applying K-Means Clustering\n",
    "\n",
    "\n",
    "For this part I Apply K-Means clustering on the processed data. The Suitble number of clusters for appling K-means is 3 . But you can uncomment the code in the bottom to run the elbow method and check the optimal number of clusters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# starting with 3 clusters\n",
    "k = 3\n",
    "#applying KMeans\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "#Fitting the model to are data \n",
    "kmeans.fit(mall_customers_normalized) \n",
    "#getting access to the cluster labels\n",
    "labels = kmeans.labels_\n",
    "#makeing a copy of the original DataFrame(to preserve the original DF)\n",
    "mall_customers_with_labels = mall_customers_to_process.copy() \n",
    "# adding the cluster labels as a new column in the original DataFrame\n",
    "mall_customers_with_labels['Cluster'] = labels  \n",
    "#retrieving the coordinates of the cluster centroids\n",
    "centroids = kmeans.cluster_centers_ \n",
    "\n",
    "\n",
    "# Converting centroids back to original feature space from the normalized space\n",
    "centroids_original = scaler.inverse_transform(centroids)  \n",
    "#Converting the centroids into a new DataFrame  with the same column names as the original DataFrame\n",
    "centroids_df = pd.DataFrame(centroids_original, columns=mall_customers_to_process.columns)\n",
    "# Assigning cluster numbers to a new column for clarity, in range of k(three clusters)\n",
    "centroids_df['Cluster'] = range(k)  \n",
    "print(centroids_df)\n",
    "print(mall_customers_with_labels.head())\n",
    "################################### finding optimal number of clusters using elbow method ##########\n",
    "\n",
    "\n",
    "# from sklearn.cluster import KMeans\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Elbow method to determine the optimal number of clusters\n",
    "# def find_optimal_clusters(data, max_k):\n",
    "#     inertia = []\n",
    "#     for k in range(1, max_k + 1):\n",
    "#         kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "#         kmeans.fit(data)\n",
    "#         inertia.append(kmeans.inertia_)\n",
    "    \n",
    "#     # Plot the elbow curve\n",
    "#     plt.figure(figsize=(8, 5))\n",
    "#     plt.plot(range(1, max_k + 1), inertia, marker='o', linestyle='--')\n",
    "#     plt.title('Elbow Method for Optimal Clusters')\n",
    "#     plt.xlabel('Number of Clusters')\n",
    "#     plt.ylabel('Inertia')\n",
    "#     plt.xticks(range(1, max_k + 1))\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "\n",
    "# # Run the elbow method to determine the optimal number of clusters\n",
    "# find_optimal_clusters(mall_customers_normalized, max_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting the results using a scatter plot. I Used`Age` as the x-axis and `Income` as the y-axis. \n",
    "\n",
    "\n",
    "The behavior each cluster represents is based on both the age and income distribution.\n",
    "1- Cluster 0 (blue) it represents middle-aged customers between 35 and 55 years old who have and average income level, and relatively good spending power.\n",
    "2- Cluster 1 (orange) describes a younger group of customers with lower income and probably a lower spending power. \n",
    "3- cluster 2 (green) corresponds to the customers with higher income and older age who can afford more expensive goods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fig_Nelliptic = plt.figure(figsize=(10, 7))\n",
    "# colors for k=3\n",
    "colors = [\"#4EACC5\", \"#FF9C34\", \"#4E9A06\"]\n",
    "\n",
    "#iterating through clusters and plotting a scatter plot of Age vs. Income for each cluster using distinct colors.\n",
    "for k, col in enumerate(colors):\n",
    "    cluster_data = mall_customers_with_labels[mall_customers_with_labels['Cluster'] == k]\n",
    "    plt.scatter(cluster_data['Age'], cluster_data['Income'], c=col, label=f'Cluster {k}', s=40, alpha=0.5)\n",
    "\n",
    "plt.scatter(centroids_df['Age'], centroids_df['Income'], c='red', s=200, marker='X', label='Centroids')\n",
    "plt.title(\"Scatter plot of Age vs. Income\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Income\")\n",
    "\n",
    "# Adding the legend\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Applying DBSCAN Clustering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "#applying DBSCAN to the normalized dataset + fitting the model\n",
    "#Started with `eps=0.5` and `min_samples=5`.\n",
    "db_Nelliptic = DBSCAN(eps=0.5, min_samples=5).fit(mall_customers_normalized)\n",
    "#predicting labels \n",
    "DBSCAN_labels_Nelliptic = db_Nelliptic.labels_\n",
    "# Number of clusters in labels, ignoring noise by excluding it from the cluster count, if present.\n",
    "n_clusters_Nelliptic = len(set(DBSCAN_labels_Nelliptic)) - (1 if -1 in DBSCAN_labels_Nelliptic else 0)\n",
    "#counting the number of noise points \n",
    "n_noise_Nelliptic = list(DBSCAN_labels_Nelliptic).count(-1)\n",
    "# Adding DBSCAN labels to mall_customers_normalized DataFrame\n",
    "mall_customers_with_dbscan_labels = mall_customers_normalized.copy()\n",
    "#storing the DBSCAN cluster labels \n",
    "mall_customers_with_dbscan_labels['DBSCAN_Cluster'] = DBSCAN_labels_Nelliptic\n",
    "\n",
    "\n",
    "display(mall_customers_with_dbscan_labels)\n",
    "print('Number of cluster labels is ',n_clusters_Nelliptic)\n",
    "\n",
    "#########################\n",
    "#Apply DBSCAN to the same dataset again to attain 3 clusters. Start with `eps=0.8` and `min_samples=8`.\n",
    "#I manually changed the values of eps and min_samples to find the right values. \n",
    "db_Nelliptic_2 = DBSCAN(eps=0.8, min_samples=8).fit(mall_customers_normalized)\n",
    "DBSCAN_labels_Nelliptic_2 = db_Nelliptic_2.labels_\n",
    "n_clusters_Nelliptic_2 = len(set(DBSCAN_labels_Nelliptic_2)) - (1 if -1 in DBSCAN_labels_Nelliptic_2 else 0)\n",
    "n_noise_Nelliptic_2 = list(DBSCAN_labels_Nelliptic_2).count(-1)\n",
    "mall_customers_with_dbscan_labels_2 = mall_customers_normalized.copy()\n",
    "mall_customers_with_dbscan_labels_2['DBSCAN_Cluster'] = DBSCAN_labels_Nelliptic_2\n",
    "\n",
    "display(mall_customers_with_dbscan_labels_2)\n",
    "print('Number of cluster labels is ',n_clusters_Nelliptic_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ploting the results in a scatter plot to Compare the results with K-Means. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results and plots,these methods have some obvious differences. K-Means has formed spherical clusters based on distances between centroids and data points, and we see the centroid in the plots. But in DBSCAN we see groups of points based on density, it also identifies noises explicitly(white points). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_Nelliptic = plt.figure(figsize=(10,10))\n",
    "ax_Nelliptic = fig_Nelliptic.add_subplot(1, 1, 1)\n",
    "#retrieves the unique cluster labels\n",
    "unique_labels_Nelliptic = set(DBSCAN_labels_Nelliptic)\n",
    "#creating a mask \n",
    "core_samples_mask_Nelliptic = np.zeros_like(DBSCAN_labels_Nelliptic, dtype=bool)\n",
    "#generating a list of distinct colors\n",
    "colors_Nelliptic = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels_Nelliptic))]\n",
    "\n",
    "#iterates through each cluster k and assigns the corresponding color \n",
    "for k, col_Nelliptic in zip(unique_labels_Nelliptic, colors_Nelliptic):\n",
    "    if k == -1:\n",
    "        # white used for noise as it was more clear to see other clusters \n",
    "        col_Nelliptic = [1, 0, 0, 0]\n",
    "    \n",
    "    #a boolean mask to identify the data points that belong to the current cluster k\n",
    "    class_member_mask_Nelliptic = DBSCAN_labels_Nelliptic == k\n",
    "    #selecting core points and plotting them\n",
    "    xy_Nelliptic = mall_customers_normalized[class_member_mask_Nelliptic & core_samples_mask_Nelliptic]\n",
    "    ax_Nelliptic.plot(\n",
    "        xy_Nelliptic['Age'],\n",
    "        xy_Nelliptic['Income'],\n",
    "        \"o\",\n",
    "        markerfacecolor=tuple(col_Nelliptic),\n",
    "        markeredgecolor=\"k\",\n",
    "        markersize=20,\n",
    "       label=f'Core point (Cluster {k})' if k != -1 else 'Noise'\n",
    "        \n",
    "    )\n",
    "    #selecting and plotting of border points with a smaller marker size\n",
    "    xy_Nelliptic = mall_customers_normalized[class_member_mask_Nelliptic & ~core_samples_mask_Nelliptic]\n",
    "    ax_Nelliptic.plot(\n",
    "        xy_Nelliptic['Age'],\n",
    "        xy_Nelliptic['Income'],\n",
    "        \"o\",\n",
    "        markerfacecolor=tuple(col_Nelliptic),\n",
    "        markeredgecolor=\"k\",\n",
    "        markersize=6,\n",
    "        label=f'Border point (Cluster {k})' if k != -1 else 'Noise'\n",
    "\n",
    "    )\n",
    "# Adding title and labels\n",
    "ax_Nelliptic.set_title('DBSCAN Clustering on Mall Customers Data')\n",
    "ax_Nelliptic.set_xlabel('Age')\n",
    "ax_Nelliptic.set_ylabel('Income')\n",
    "# Adding legends\n",
    "ax_Nelliptic.legend()\n",
    "ax_Nelliptic.set_title('DBSCAN clustering on a Non-elliptic dataset')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "########################################\n",
    "#plotting the second DBSCAN\n",
    "fig_Nelliptic_2 = plt.figure(figsize=(10,10))\n",
    "ax_Nelliptic_2 = fig_Nelliptic_2.add_subplot(1, 1, 1)\n",
    "unique_labels_Nelliptic_2 = set(DBSCAN_labels_Nelliptic_2)\n",
    "core_samples_mask_Nelliptic_2 = np.zeros_like(DBSCAN_labels_Nelliptic_2, dtype=bool)\n",
    "\n",
    "colors_Nelliptic = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels_Nelliptic_2))]\n",
    "\n",
    "\n",
    "for k, col_Nelliptic in zip(unique_labels_Nelliptic_2, colors_Nelliptic):\n",
    "    if k == -1:\n",
    "        # white used for noise as it was more clear to see other clusters \n",
    "        col_Nelliptic = [1, 0, 0, 0]\n",
    "    \n",
    "\n",
    "    class_member_mask_Nelliptic_2 = DBSCAN_labels_Nelliptic_2 == k\n",
    "\n",
    "    xy_Nelliptic_2 = mall_customers_normalized[class_member_mask_Nelliptic_2 & core_samples_mask_Nelliptic_2]\n",
    "    ax_Nelliptic_2.plot(\n",
    "        xy_Nelliptic_2['Age'],\n",
    "        xy_Nelliptic_2['Income'],\n",
    "        \"o\",\n",
    "        markerfacecolor=tuple(col_Nelliptic),\n",
    "        markeredgecolor=\"k\",\n",
    "        markersize=20,\n",
    "       label=f'Core point (Cluster {k})' if k != -1 else 'Noise'\n",
    "        \n",
    "    )\n",
    "    xy_Nelliptic_2= mall_customers_normalized[class_member_mask_Nelliptic_2 & ~core_samples_mask_Nelliptic_2]\n",
    "    ax_Nelliptic_2.plot(\n",
    "        xy_Nelliptic_2['Age'],\n",
    "        xy_Nelliptic_2['Income'],\n",
    "        \"o\",\n",
    "        markerfacecolor=tuple(col_Nelliptic),\n",
    "        markeredgecolor=\"k\",\n",
    "        markersize=6,\n",
    "        label=f'Border point (Cluster {k})' if k != -1 else 'Noise'\n",
    "\n",
    "    )\n",
    "# Adding title and labels\n",
    "ax_Nelliptic_2.set_title('DBSCAN Clustering on Mall Customers Data')\n",
    "ax_Nelliptic_2.set_xlabel('Age')\n",
    "ax_Nelliptic_2.set_ylabel('Income')\n",
    "# Adding legends\n",
    "ax_Nelliptic_2.legend()\n",
    "ax_Nelliptic_2.set_title('DBSCAN clustering on a Non-elliptic dataset')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Evaluation of the methods with silhouette scores for both K-Means and DBSCAN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Silhouette score for K-Means\n",
    "copy_mall = mall_customers_normalized\n",
    "kmeans_silhouette_score = silhouette_score(copy_mall, labels)\n",
    "print('kmeans_silhouette_score:',kmeans_silhouette_score)\n",
    "\n",
    "################################################\n",
    "# without excluding the noise got the score\n",
    "copy_mall2 = mall_customers_normalized\n",
    "dbscan_silhouette_score = silhouette_score(mall_customers_normalized, DBSCAN_labels_Nelliptic)\n",
    "print('dbscan_silhouette_score including noise points:',dbscan_silhouette_score)\n",
    "##################################################\n",
    "copy_mall3 = mall_customers_normalized\n",
    "\n",
    "# Exclude noise points (labeled as -1)\n",
    "filtered_data = copy_mall3[DBSCAN_labels_Nelliptic != -1]\n",
    "filtered_labels = DBSCAN_labels_Nelliptic[DBSCAN_labels_Nelliptic != -1]\n",
    "\n",
    "# Calculate silhouette score only for non-noise points\n",
    "dbscan_silhouette_score = silhouette_score(filtered_data, filtered_labels)\n",
    "print('dbscan_silhouette_score for non-noise points:',dbscan_silhouette_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Silhouette score of each clustering method I draw conclusions as following :\n",
    "\n",
    "- The score of 0.2 for K-Means indicates that the clusters are well seperated but have overlapp each other(we see it in the plotting as well)\n",
    "- The negative Silhouette score for DBSCAN method shows a poor clustering performance on the dataset. Eventhough I excluded the noises the second time , the score is very close to 0 and doesn't make a remarkable difference.\n",
    "\n",
    "K-means strenghs are in forming well-seperated clusters, clear datapoints around the centroids and the shape of clusters (elliptical or spherical). However, it shows weakness as it's sensitive to outliers and it includes many outliers to the clusters (green cluster in exercise 4)\n",
    "\n",
    "DBSAN's strength lies in its ability to handle clusters of arbitary shapes and sizes , identifying noise (white datapoints) and not needing the predefinition of cluster numbers, it discovers that itself. but the weaknes of this method is the sensitivity it has for on the input parameters , eps and min_samples to determine the number of clusters. It took time to find the right combination.Another weakness was that the method was not able to vary densities correctly that ked to unmerged clusters after plotting.\n",
    "\n",
    "\n",
    "The reason behind the low scores can be the presens of high noise level in our data. after plotting the data, and applying DBSCAN method, it was obvious that noises have a lot of impact in the clustering process and the visuallization is not clear.\n",
    "\n",
    "In summary, the clustering results indicate that K-Means provides a better clustering solution than DBSCAN for the dataset based on the silhouette scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
